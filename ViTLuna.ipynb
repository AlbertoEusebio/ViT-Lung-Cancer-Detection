{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11474173,"sourceType":"datasetVersion","datasetId":7191103}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:01.139089Z","iopub.execute_input":"2025-04-20T01:01:01.139980Z","iopub.status.idle":"2025-04-20T01:01:01.144141Z","shell.execute_reply.started":"2025-04-20T01:01:01.139954Z","shell.execute_reply":"2025-04-20T01:01:01.143372Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/luna16-2dslices/nodule_metadata.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:01.145578Z","iopub.execute_input":"2025-04-20T01:01:01.145883Z","iopub.status.idle":"2025-04-20T01:01:01.207839Z","shell.execute_reply.started":"2025-04-20T01:01:01.145855Z","shell.execute_reply":"2025-04-20T01:01:01.207268Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                           seriesuid  ann_idx    z    y    x  \\\n0  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...        0  266  328  173   \n1  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...        1  252  293  220   \n2  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...        2  230  251  379   \n3  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...        3  142  336  377   \n4  1.3.6.1.4.1.14519.5.2.1.6279.6001.100953483028...        0   76  289  354   \n\n                                            filename  label  \n0  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...      1  \n1  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...      1  \n2  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...      1  \n3  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...      1  \n4  1.3.6.1.4.1.14519.5.2.1.6279.6001.100953483028...      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seriesuid</th>\n      <th>ann_idx</th>\n      <th>z</th>\n      <th>y</th>\n      <th>x</th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>0</td>\n      <td>266</td>\n      <td>328</td>\n      <td>173</td>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>1</td>\n      <td>252</td>\n      <td>293</td>\n      <td>220</td>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>2</td>\n      <td>230</td>\n      <td>251</td>\n      <td>379</td>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>3</td>\n      <td>142</td>\n      <td>336</td>\n      <td>377</td>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100953483028...</td>\n      <td>0</td>\n      <td>76</td>\n      <td>289</td>\n      <td>354</td>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100953483028...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"## we filter thoe that are not nodules\n\ndf = df[df['label'] == 1]\ndf['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:01.208468Z","iopub.execute_input":"2025-04-20T01:01:01.208664Z","iopub.status.idle":"2025-04-20T01:01:01.215455Z","shell.execute_reply.started":"2025-04-20T01:01:01.208650Z","shell.execute_reply":"2025-04-20T01:01:01.214613Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"label\n1    606\nName: count, dtype: int64"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"len(set(df['seriesuid'])), len(df['seriesuid'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:01.216742Z","iopub.execute_input":"2025-04-20T01:01:01.216949Z","iopub.status.idle":"2025-04-20T01:01:01.230204Z","shell.execute_reply.started":"2025-04-20T01:01:01.216926Z","shell.execute_reply":"2025-04-20T01:01:01.229522Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(311, 606)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"class LunaDataset(Dataset):\n    \n    def __init__(self, dataframe, data_path, transforms=None):\n        self.df = dataframe\n        self.data_path = data_path\n        self.transforms = transforms\n\n        self.X = []\n        self.y = []\n        self.__load_dataset()\n\n    def __load_file_images(self, filename):\n        blob = np.load(filename)\n        img = blob['arr_0']\n        img = np.stack([img, img, img])\n        self.X.append(img)\n\n    \n    def __load_dataset(self):\n        self.df['filename'].apply(lambda f: self.__load_file_images(os.path.join(self.data_path, f)))\n        cx = self.df['x']\n        cy = self.df['y']\n\n        self.X = np.array(self.X)\n        self.y = np.stack([cx, cy], axis=-1)\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, i):\n\n        img, label = self.X[i], self.y[i]\n\n        img = torch.tensor(img)\n\n        min_v = img.min()\n        max_v = img.max()\n\n        img = (img - min_v)/(max_v - min_v)\n        \n        if self.transforms:\n            img = img.unsqueeze(0)\n            img = self.transforms(img)\n            img = img.squeeze(0)\n        \n        label = torch.tensor(label)\n        label = label / 512 * 224\n        \n        return img, label","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:01.230928Z","iopub.execute_input":"2025-04-20T01:01:01.231135Z","iopub.status.idle":"2025-04-20T01:01:01.246552Z","shell.execute_reply.started":"2025-04-20T01:01:01.231099Z","shell.execute_reply":"2025-04-20T01:01:01.245851Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"patients = list(set(df['seriesuid']))\nl = len(patients)\nt = int(0.8*l)\ntrain_patients = patients[:t]\nval_patients = patients[t:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:01.247277Z","iopub.execute_input":"2025-04-20T01:01:01.247555Z","iopub.status.idle":"2025-04-20T01:01:01.261554Z","shell.execute_reply.started":"2025-04-20T01:01:01.247530Z","shell.execute_reply":"2025-04-20T01:01:01.260901Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"len(train_patients), len(val_patients), len(train_patients) + len(val_patients)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:01.262569Z","iopub.execute_input":"2025-04-20T01:01:01.262807Z","iopub.status.idle":"2025-04-20T01:01:01.275865Z","shell.execute_reply.started":"2025-04-20T01:01:01.262785Z","shell.execute_reply":"2025-04-20T01:01:01.275097Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(248, 63, 311)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"train_df = df[df['seriesuid'].isin(train_patients)]\nval_df = df[df['seriesuid'].isin(val_patients)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:01.276854Z","iopub.execute_input":"2025-04-20T01:01:01.277088Z","iopub.status.idle":"2025-04-20T01:01:01.289812Z","shell.execute_reply.started":"2025-04-20T01:01:01.277068Z","shell.execute_reply":"2025-04-20T01:01:01.289179Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])\n\ntrain_dataset = LunaDataset(train_df, '/kaggle/input/luna16-2dslices/dataset', transform)\nval_dataset = LunaDataset(val_df, '/kaggle/input/luna16-2dslices/dataset', transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:01.291458Z","iopub.execute_input":"2025-04-20T01:01:01.291966Z","iopub.status.idle":"2025-04-20T01:01:04.813784Z","shell.execute_reply.started":"2025-04-20T01:01:01.291949Z","shell.execute_reply":"2025-04-20T01:01:04.813237Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"img, label = train_dataset[0]\nimg.shape, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:04.814513Z","iopub.execute_input":"2025-04-20T01:01:04.814773Z","iopub.status.idle":"2025-04-20T01:01:04.823893Z","shell.execute_reply.started":"2025-04-20T01:01:04.814749Z","shell.execute_reply":"2025-04-20T01:01:04.823335Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(torch.Size([3, 224, 224]), tensor([ 75.6875, 143.5000]))"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"from torchvision import models\nimport torch.nn as nn\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 🔧 Load torchvision ViT\nmodel = models.vit_b_16(pretrained=True)\n# model = models.resnet50(pretrained=True)\nmodel.heads.head = nn.Sequential(\n    nn.Linear(model.heads.head.in_features, 128),\n    nn.ReLU(),\n    nn.Linear(128, 2)\n)  # Output: x, y coordinates\nmodel.to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:04.824501Z","iopub.execute_input":"2025-04-20T01:01:04.824687Z","iopub.status.idle":"2025-04-20T01:01:06.123501Z","shell.execute_reply.started":"2025-04-20T01:01:04.824672Z","shell.execute_reply":"2025-04-20T01:01:06.122830Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"VisionTransformer(\n  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n  (encoder): Encoder(\n    (dropout): Dropout(p=0.0, inplace=False)\n    (layers): Sequential(\n      (encoder_layer_0): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_1): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_2): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_3): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_4): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_5): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_6): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_7): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_8): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_9): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_10): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_11): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n  )\n  (heads): Sequential(\n    (head): Sequential(\n      (0): Linear(in_features=768, out_features=128, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=128, out_features=2, bias=True)\n    )\n  )\n)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"from tqdm import tqdm\n\nEPOCHS = 100\nLR = 1e-3\n\ncriterion = nn.SmoothL1Loss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n\nfor epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0.0\n    \n    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Training\"):\n        images = images.to(DEVICE)\n        labels = labels.float().to(DEVICE)  # shape: (B, 2)\n\n        images = images.unsqueeze(1) if images.ndim == 3 else images\n\n        optimizer.zero_grad()\n        outputs = model(images)  # shape: (B, 2)\n        # print(outputs, labels)\n        \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item() * images.size(0)\n\n    avg_train_loss = total_loss / len(train_loader.dataset)\n    print(f\"Train Loss: {avg_train_loss:.4f}\")\n\n    # 📉 Validation\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Validation\"):\n            images = images.to(DEVICE)\n            labels = labels.float().to(DEVICE)\n\n            images = images.unsqueeze(1) if images.ndim == 3 else images\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n\n    avg_val_loss = val_loss / len(val_loader.dataset)\n\n    scheduler.step(avg_val_loss)\n    print(f\"Val Loss: {avg_val_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T01:01:06.124172Z","iopub.execute_input":"2025-04-20T01:01:06.124374Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 68.2989\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 41.2038\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 37.4567\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1982\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 37.0897\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.0697\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 37.2526\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 38.7696\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.9208\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.8232\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 37.2062\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 38.8896\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 37.1986\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.2376\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 37.2060\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.2290\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 37.1921\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.6170\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 37.3005\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.9827\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.9260\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.3461\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.8172\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1710\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.8217\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.2194\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.8198\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1593\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7852\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1751\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7953\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.0697\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7654\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.0775\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7644\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.0829\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7668\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.0909\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7651\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.0923\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7657\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.0972\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7660\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1019\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7615\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1006\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7616\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 13.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1005\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7616\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1022\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7620\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1021\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7615\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1018\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7617\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1025\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7613\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 13.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1024\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7613\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1025\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7613\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1024\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7613\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1024\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7613\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1026\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7613\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1025\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7612\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1025\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7612\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1025\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7612\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1025\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7612\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1025\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7612\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 14.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1025\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/100 - Training: 100%|██████████| 59/59 [00:11<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36.7612\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/100 - Validation: 100%|██████████| 18/18 [00:01<00:00, 15.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 39.1026\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/100 - Training:   8%|▊         | 5/59 [00:00<00:10,  5.24it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nmodel.eval()\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(DEVICE), labels.float().to(DEVICE)\n        images = images.unsqueeze(1) if images.ndim == 3 else images\n\n        outputs = model(images)  # shape: (B, 2)\n        \n        plt.figure()\n        plt.imshow(images[0].cpu().permute(1, 2, 0).mean(axis=-1) * 0.5 + 0.5, cmap='gray')\n        x, y = outputs[0].cpu()\n        a, b = labels[0].cpu()\n        print(x, y, a, b)\n        \n        plt.plot(x, y, 'bo', markersize=5)\n        plt.plot(a, b, 'ro', markersize=5)\n\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(outputs.cpu().numpy())\n\n# Convert to numpy arrays\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# MSE\nmse = mean_squared_error(y_true, y_pred)\nprint(f\"Mean Squared Error: {mse:.4f}\")\n\n# Euclidean distance per point\ndistances = np.linalg.norm((y_true - y_pred), axis=1)\nmean_distance = distances.mean()\nprint(f\"Mean Euclidean Distance: {mean_distance:.2f} pixels\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}